{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 분할\n",
    "\n",
    "이전 [노트북](https://github.com/rickiepark/ml-powered-applications/blob/master/notebooks/dataset_exploration.ipynb)에서 데이터셋을 탐색했습니다. 이제 이 데이터셋을 훈련 세트와 테스트 세트로 분할하겠습니다. 데이터셋을 분할하는 것은 모델의 성능을 검증하는데 매우 중요합니다. 일부 데이터로만 모델을 훈련하고 모델의 실전 성능이 얼마나 될지 추정하기 위해 본 적 없는 데이터를 사용할 수 있습니다.\n",
    "\n",
    "이 노트북에서 `writer` 스택 오버플로 데이터셋을 사용해 몇 가지 분할 방법을 소개합니다. 먼저 데이터를 로드하고 전처리합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def format_raw_df(df):\n",
    "    \"\"\"\n",
    "    데이터를 정제하고 질문과 대답을 합칩니다.\n",
    "    \"\"\"\n",
    "    df[\"PostTypeId\"] = df[\"PostTypeId\"].astype(int)\n",
    "    df[\"Id\"] = df[\"Id\"].astype(int)\n",
    "    df[\"AnswerCount\"] = df[\"AnswerCount\"].fillna(-1)\n",
    "    df[\"AnswerCount\"] = df[\"AnswerCount\"].astype(int)\n",
    "    df[\"OwnerUserId\"].fillna(-1, inplace=True)\n",
    "    df[\"OwnerUserId\"] = df[\"OwnerUserId\"].astype(int)\n",
    "    df.set_index(\"Id\", inplace=True, drop=False)\n",
    "\n",
    "    df[\"is_question\"] = df[\"PostTypeId\"] == 1\n",
    "\n",
    "    # 문서화된 것 이외의 PostTypeId를 필터링한다\n",
    "    df = df[df[\"PostTypeId\"].isin([1, 2])]\n",
    "\n",
    "    # 질문과 대답을 연결합니다\n",
    "    df = df.join(\n",
    "        df[[\"Id\", \"Title\", \"body_text\", \"Score\", \"AcceptedAnswerId\"]],\n",
    "        on=\"ParentId\",\n",
    "        how=\"left\",\n",
    "        rsuffix=\"_question\",\n",
    "    )\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_random_train_test_split(posts, test_size=0.3, random_state=40):\n",
    "    \"\"\"\n",
    "    DataFrame을 훈련/테스트 세트로 나눕니다.\n",
    "    DataFrame이 질문마다 하나의 행을 가진다고 가정합니다.\n",
    "    :param posts: 모든 포스트와 레이블\n",
    "    :param test_size: 테스트 세트로 할당할 비율\n",
    "    :param random_state: 랜덤 시드\n",
    "    \"\"\"\n",
    "    return train_test_split(\n",
    "        posts, test_size=test_size, random_state=random_state\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_vectorized_inputs_and_label(df):\n",
    "    \"\"\"\n",
    "    DataFrame 특성과 텍스트 벡터를 연결합니다.\n",
    "    :param df: 계산된 특성의 DataFrame\n",
    "    :return: 특성과 텍스트로 구성된 벡터\n",
    "    \"\"\"\n",
    "    vectorized_features = np.append(\n",
    "        np.vstack(df[\"vectors\"]),\n",
    "        df[\n",
    "            [\n",
    "                \"action_verb_full\",\n",
    "                \"question_mark_full\",\n",
    "                \"norm_text_len\",\n",
    "                \"language_question\",\n",
    "            ]\n",
    "        ],\n",
    "        1,\n",
    "    )\n",
    "    label = df[\"Score\"] > df[\"Score\"].median()\n",
    "\n",
    "    return vectorized_features, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def get_split_by_author(\n",
    "    posts, author_id_column=\"OwnerUserId\", test_size=0.3, random_state=40\n",
    "):\n",
    "    \"\"\"\n",
    "    훈련 세트와 테스트 세트로 나눕니다.\n",
    "    작성자가 두 세트 중에 하나에만 등장하는 것을 보장합니다.\n",
    "    :param posts: 모든 포스트와 레이블\n",
    "    :param author_id_column: author_id가 들어 있는 열 이름\n",
    "    :param test_size: 테스트 세트로 할당할 비율\n",
    "    :param random_state: 랜덤 시드\n",
    "    \"\"\"\n",
    "    splitter = GroupShuffleSplit(\n",
    "        n_splits=1, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    splits = splitter.split(posts, groups=posts[author_id_column])\n",
    "    train_idx, test_idx = next(splits)\n",
    "    return posts.iloc[train_idx, :], posts.iloc[test_idx, :]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import umap\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = Path('data/writers.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "df = format_raw_df(df.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33650 entries, 1 to 42885\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Unnamed: 0                 33650 non-null  int64  \n",
      " 1   AcceptedAnswerId           4124 non-null   float64\n",
      " 2   AnswerCount                33650 non-null  int64  \n",
      " 3   Body                       33650 non-null  object \n",
      " 4   ClosedDate                 969 non-null    object \n",
      " 5   CommentCount               33650 non-null  int64  \n",
      " 6   CommunityOwnedDate         186 non-null    object \n",
      " 7   CreationDate               33650 non-null  object \n",
      " 8   FavoriteCount              3307 non-null   float64\n",
      " 9   Id                         33650 non-null  int64  \n",
      " 10  LastActivityDate           33650 non-null  object \n",
      " 11  LastEditDate               10521 non-null  object \n",
      " 12  LastEditorDisplayName      606 non-null    object \n",
      " 13  LastEditorUserId           9975 non-null   float64\n",
      " 14  OwnerDisplayName           1970 non-null   object \n",
      " 15  OwnerUserId                33650 non-null  int64  \n",
      " 16  ParentId                   25679 non-null  float64\n",
      " 17  PostTypeId                 33650 non-null  int64  \n",
      " 18  Score                      33650 non-null  int64  \n",
      " 19  Tags                       7971 non-null   object \n",
      " 20  Title                      7971 non-null   object \n",
      " 21  ViewCount                  7971 non-null   float64\n",
      " 22  body_text                  33650 non-null  object \n",
      " 23  is_question                33650 non-null  bool   \n",
      " 24  Id_question                25679 non-null  float64\n",
      " 25  Title_question             25679 non-null  object \n",
      " 26  body_text_question         25679 non-null  object \n",
      " 27  Score_question             25679 non-null  float64\n",
      " 28  AcceptedAnswerId_question  14382 non-null  float64\n",
      "dtypes: bool(1), float64(8), int64(7), object(13)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 랜덤 분할\n",
    "\n",
    "테스트 세트를 만드는 가장 간단한 방법은 랜덤하게 데이터를 훈련 세트와 테스트 세트로 나누는 것입니다. 방식은 다음과 같습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_df_rand, test_df_rand = get_random_train_test_split(df[df[\"is_question\"]], test_size=0.3, random_state=40)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트: 5579개 질문, 테스트 세트: 2392개 질문\n",
      "훈련 세트에 있는 작성자: 2955명\n",
      "테스트 세트에 있는 작성자: 1531명\n",
      "양쪽에 모두 등장하는 작성자: 596명\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트: %s개 질문, 테스트 세트: %s개 질문\" % (len(train_df_rand), len(test_df_rand)))\n",
    "train_owners = set(train_df_rand['OwnerUserId'].values)\n",
    "test_owners = set(test_df_rand['OwnerUserId'].values)\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(train_owners))\n",
    "print(\"테스트 세트에 있는 작성자: %s명\" % len(test_owners))\n",
    "print(\"양쪽에 모두 등장하는 작성자: %s명\" % len(train_owners.intersection(test_owners)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "이 방식은 한 가지 단점이 있습니다. 다음 섹션으로 넘어가기 전에 이 단점이 무엇인지 생각해 보세요."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 작성자를 기준으로 분할하기\n",
    "\n",
    "어떤 작성자는 다른 사람보다 질문을 작성하는데 더 뛰어날 수 있습니다. 한 작성자가 훈련 세트와 테스트 세트에 모두 등장하면 모델이 작성자를 인식하여 간단히 질문의 점수를 예측할 수 있습니다. 단순하게 특성에서 `AuthorId`를 삭제하는 것은 이 문제를 완전히 해결하지 못합니다. 질문에 저자의 특징이 포함되어 있을 수 있기 때문입니다(특히 일부 작성자는 자기 사인을 질문에 포함시킵니다).\n",
    "\n",
    "질문의 품질을 정확하게 판단하기 위해서 한 작성자는 훈련 세트나 검증 세트 하나에만 등장해야 합니다. 이를 통해 모델이 저자를 식별할 수 있는 정보를 사용하여 쉽게 예측을 하지 못하게 만들 수 있습니다.\n",
    "\n",
    "이런 잠재적인 편향의 원인을 제거하기 위해 작성자를 기준으로 분할하겠습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트: 5676개 질문, 테스트 세트: 2295개 질문\n",
      "훈련 세트에 있는 작성자: 2723명\n",
      "훈련 세트에 있는 작성자: 1167명\n",
      "양쪽에 모두 등장하는 작성자: 0명\n"
     ]
    }
   ],
   "source": [
    "train_author, test_author = get_split_by_author(df[df[\"is_question\"]], test_size=0.3, random_state=40)\n",
    "\n",
    "print(\"훈련 세트: %s개 질문, 테스트 세트: %s개 질문\" % (len(train_author),len(test_author)))\n",
    "train_owners = set(train_author['OwnerUserId'].values)\n",
    "test_owners = set(test_author['OwnerUserId'].values)\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(train_owners))\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(test_owners))\n",
    "print(\"양쪽에 모두 등장하는 작성자: %s명\" % len(train_owners.intersection(test_owners)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "여기서는 작성자를 기준으로 분할하지만 다른 유형의 데이터를 위한 분할 방법이 여러 가지가 있습니다. 예를 들어 어떤 기간 동안 쓰여진 질문에서 훈련하면 최근에 질문에 잘 동작하는 모델을 만들 수 있는지 확인하기 위해 시간 기분으로 분할할 수 있습니다. 더 자세한 내용은 책을 참고하세요."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
